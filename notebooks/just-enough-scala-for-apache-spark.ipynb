{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "There are quite few ways to setup environment to try spark. Here comes two easy ways, to try it.\n",
    "\n",
    "### Local Environment with Jupyter + Spylon-kernel\n",
    "\n",
    "1. Install JDK\n",
    "2. Download and install [spark](http://spark.apache.org/downloads.html)\n",
    "3. Download and instal [Anaconda 3](https://www.anaconda.com/distribution/#download-section)\n",
    "4. Install [Spylon-Kernel](https://github.com/Valassis-Digital-Media/spylon-kernel)\n",
    "5. Start Jupyter by `jupyter notebook`\n",
    "\n",
    "### Using [Databricks](https://databricks.com/try-databricks)\n",
    "\n",
    "Databricks is a company founded by the creators of Apache Spark, that aims to help clients with cloud-based big data processing using Spark. Databricks grew out of the AMPLab project at University of California, Berkeley that was involved in making Apache Spark, a distributed computing framework built atop Scala\n",
    "\n",
    "Databricks also offer community version, which can try out Spark. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value and Variable\n",
    "\n",
    "Scala has two kinds of variables, vals and vars. A val is similar to a final variable in Java. Once initialized, a val can never be reassigned. A var, by contrast, is similar to a non-final variable in Java. A var can be reassigned throughout its lifetime. Here's a val definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value: String = Hello World\n",
       "variable: String = Hello World again\n",
       "variable: String = Hello World again\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val value = \"Hello World\"\n",
    "var variable = \"Hello World\"\n",
    "variable = \"Hello World again\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scala is a static type language. In the previous example, there are no type provided. While the type will be automatically infered. We can, provide type explicitly if makes the code more clear. \n",
    "\n",
    "The following code has exactly same effect as previous code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value: String = Hello World\n",
       "variable: String = Hello World again\n",
       "variable: String = Hello World again\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val value: String = \"Hello World\"\n",
    "var variable: String = \"Hello World\"\n",
    "variable = \"Hello World again\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primitive Types\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "boolean_value: Boolean = true\n",
       "int_value: Int = 3\n",
       "long_value: Long = 3\n",
       "double_value: Double = 3.0\n",
       "float_value: Float = 3.0\n",
       "string_value: String = hello\n",
       "byte_value: Byte = 3\n",
       "short_value: Short = 3\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val boolean_value = true\n",
    "val int_value     = 3\n",
    "val long_value    = 3L\n",
    "val double_value  = 3.0\n",
    "val float_value   = 3.0f\n",
    "val string_value  = \"hello\"\n",
    "val byte_value: Byte   = 3\n",
    "val short_value: Short = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple_2_value: (Int, Int) = (1,2)\n",
       "tuple_3_value: (Int, Int, Int) = (1,2,3)\n",
       "tuple_different_types: (Int, String) = (1,hello)\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tuple_2_value = (1, 2)\n",
    "val tuple_3_value = (1, 2, 3)\n",
    "val tuple_different_types = (1, \"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for (v <- tuple_2_value.productIterator) {\n",
    "    println(v)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list_value: List[Int] = List(1, 2, 3)\n",
       "list_not_same_type: List[Any] = List(1, Hello)\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val list_value = List(1, 2, 3)\n",
    "val list_not_same_type = List(1, \"Hello\")\n",
    "\n",
    "for (v <- list_value) {\n",
    "    println(v)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "map_value: scala.collection.immutable.Map[String,String] = Map(name -> Rockie, like -> Simple)\n",
       "name: String = Rockie\n",
       "keys: Iterable[String] = Set(name, like)\n",
       "values: Iterable[String] = MapLike(Rockie, Simple)\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val map_value = Map(\"name\" -> \"Rockie\", \"like\" -> \"Simple\")\n",
    "\n",
    "val name = map_value(\"name\")\n",
    "\n",
    "val keys = map_value.keys\n",
    "val values = map_value.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(name,Rockie)\n",
      "(like,Simple)\n"
     ]
    }
   ],
   "source": [
    "for ((key, value) <- map_value) {\n",
    "    println(key, value)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello Spark\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fun_no_parameter_no_value: ()Unit\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-26 21:03:05 WARN  HeartbeatReceiver:66 - Removing executor driver with no recent heartbeats: 146333 ms exceeds timeout 120000 ms\n",
      "2019-03-26 21:03:05 ERROR TaskSchedulerImpl:70 - Lost an executor driver (already removed): Executor heartbeat timed out after 146333 ms\n",
      "2019-03-26 21:03:05 WARN  SparkContext:66 - Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "def fun_no_parameter_no_value() = {\n",
    "    println(\"hello Spark\")\n",
    "}\n",
    "fun_no_parameter_no_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello Spark\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fun_no_value: (name: String)Unit\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fun_no_value(name: String) = {\n",
    "    println(\"hello \" + name)\n",
    "}\n",
    "\n",
    "fun_no_value(\"Spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello Spark\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fun: (name: String)String\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fun(name: String) = {\n",
    "    \"hello \" + name\n",
    "}\n",
    "\n",
    "println(fun(\"Spark\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "// 相当于singleton\n",
    "object HelloWorld {\n",
    "    // object里的函数相当于静态函数\n",
    "    // args 参数名\n",
    "    // Array[String] 参数类型\n",
    "    // Unit 返回类型，相当于java的void\n",
    "    def main(args: Array[String]): Unit = {\n",
    "        // 定义字符串常量，相当于java的\n",
    "        // final String exp = \"Hello World\";\n",
    "        val exp: String = \"Hello World\"\n",
    " \n",
    "        // 编译器可以侦测到的类型不需要显式定义类型.\n",
    "        // 所以也可以写成下面的方式\n",
    "        // scala中有很多都可以省略，新做的编译器智能化多了.\n",
    "        // 最后的分号也是可以省略的。\n",
    "        // 不过Scala的Eclipse的插件如果没有；就会缩进。\n",
    "        val imp = \"Hello World\"\n",
    " \n",
    "        // 定义变量，相当于java的\n",
    "        // String v = \"Hello\"\n",
    "        var v = \"Hello\"\n",
    "        v += \" World\"\n",
    " \n",
    "        // 打印。相当于java的\n",
    "        // System.out.println(v);\n",
    "        println(v)\n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
